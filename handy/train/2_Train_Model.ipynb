{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handy\n",
    "## Train model\n",
    "\n",
    "Now let's train the model. Handy trains it using a whole variety of classification models and then chooses which one works the best. I decided to go with a lot of different models to learn how each of them work.\n",
    "* [Random Forest (decision trees)](https://en.wikipedia.org/wiki/Random_forest)\n",
    "* [Gradient Boosting](https://en.wikipedia.org/wiki/Gradient_boosting)\n",
    "* [Stochastic Gradient Descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent)\n",
    "* [Decision Tree](https://en.wikipedia.org/wiki/Decision_tree)\n",
    "* [Naive Bayes Classifier](https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n",
    "* [K-nearest Neighbors Algorithm](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)\n",
    "* [Support Vector Classifier (SVC)](https://en.wikipedia.org/wiki/Support_vector_machine)\n",
    "* [Linear Support Vector Classifier (LinearSVC)](https://en.wikipedia.org/wiki/Support_vector_machine#Linear_SVM)\n",
    "* [Linear Discriminant Analysis](https://en.wikipedia.org/wiki/Linear_discriminant_analysis)\n",
    "* [Quadratic Discriminant Analysis](https://en.wikipedia.org/wiki/Quadratic_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in d:\\apps\\anaconda3\\envs\\handy\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in d:\\apps\\anaconda3\\envs\\handy\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\artur\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\artur\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\apps\\anaconda3\\envs\\handy\\lib\\site-packages (from scikit-learn) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import make_pipeline \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class_name\n",
       "0    200\n",
       "1    200\n",
       "2    200\n",
       "3    199\n",
       "4    176\n",
       "5    196\n",
       "6    158\n",
       "7    197\n",
       "8    199\n",
       "9    196\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "\n",
    "from os import path\n",
    "\n",
    "\n",
    "if not path.exists(\"data.csv\"):\n",
    "    print(\"The data.csv file doesn't exist! Please first come through the 2_Process_Data.ipynb notebook.\")\n",
    "    exit(-1)\n",
    "\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "X = df.drop(\"class_name\", axis=1)\n",
    "y = df[\"class_name\"]\n",
    "\n",
    "# Number of data per class\n",
    "df.groupby(\"class_name\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1728\n",
      "Test: 193\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=2)\n",
    "\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "print(f\"Train: {len(X_train)}\")\n",
    "print(f\"Test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         angle_0     angle_1     angle_2     angle_3\n",
      "844   179.873997  169.216289    7.005674  177.978082\n",
      "1828  167.104811  179.071756   80.086742   93.292244\n",
      "1369  163.199372  179.062881   72.913115    5.932791\n",
      "4     177.297062  176.462795    8.410298    8.085928\n",
      "426   178.072259   82.373054    9.622006   71.537795\n",
      "...          ...         ...         ...         ...\n",
      "1282  162.356705  164.553184  158.741131  157.443774\n",
      "1339  164.967706  178.128011   71.234268    5.698393\n",
      "1055  174.122265  176.673479   11.737375  155.368424\n",
      "1783  179.124347  173.213055  115.996727  117.650164\n",
      "445   177.478903   79.389113   10.371008   71.939602\n",
      "\n",
      "[193 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    \"RandomForestClassifier\": make_pipeline(StandardScaler(), RandomForestClassifier(criterion=\"log_loss\", max_depth=8, n_estimators=30, random_state=7)),\n",
    "    \"GradientBoostingClassifier\": make_pipeline(StandardScaler(), GradientBoostingClassifier()),\n",
    "    \"SGDClassifier\": make_pipeline(StandardScaler(), SGDClassifier()),\n",
    "    \"DecisionTreeClassifier\": make_pipeline(StandardScaler(), DecisionTreeClassifier()),\n",
    "    \"GaussianNB\": make_pipeline(StandardScaler(), GaussianNB()),\n",
    "    \"KNeighborsClassifier\": make_pipeline(StandardScaler(), KNeighborsClassifier()),\n",
    "    \"SVC\": make_pipeline(StandardScaler(), SVC()),\n",
    "    \"LinearSVC\": make_pipeline(StandardScaler(), LinearSVC()),\n",
    "    \"LinearDiscriminantAnalysis\": make_pipeline(StandardScaler(), LinearDiscriminantAnalysis()),\n",
    "    \"QuadraticDiscriminantAnalysis\": make_pipeline(StandardScaler(), QuadraticDiscriminantAnalysis()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RandomForestClassifier]: accuracy = 1.0\n",
      "[RandomForestClassifier]: log loss = 0.009605406241126959\n",
      "[GradientBoostingClassifier]: accuracy = 0.9948186528497409\n",
      "[GradientBoostingClassifier]: log loss = 0.0634269639671492\n",
      "[SGDClassifier]: accuracy = 0.9326424870466321\n",
      "[DecisionTreeClassifier]: accuracy = 1.0\n",
      "[DecisionTreeClassifier]: log loss = 1.998401444325284e-15\n",
      "[GaussianNB]: accuracy = 0.9792746113989638\n",
      "[GaussianNB]: log loss = 0.2230335127098297\n",
      "[KNeighborsClassifier]: accuracy = 1.0\n",
      "[KNeighborsClassifier]: log loss = 1.998401444325284e-15\n",
      "[SVC]: accuracy = 0.9896373056994818\n",
      "[LinearSVC]: accuracy = 0.917098445595855\n",
      "[LinearDiscriminantAnalysis]: accuracy = 0.9119170984455959\n",
      "[LinearDiscriminantAnalysis]: log loss = 0.3275876472915633\n",
      "[QuadraticDiscriminantAnalysis]: accuracy = 0.9948186528497409\n",
      "[QuadraticDiscriminantAnalysis]: log loss = 0.021457710420767537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\Anaconda3\\envs\\handy\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2916: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "d:\\apps\\Anaconda3\\envs\\handy\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "models = {}\n",
    "\n",
    "for name, algorithm in pipelines.items():\n",
    "    model = algorithm.fit(X_train.values, y_train.values)\n",
    "\n",
    "    # Calculate the metrics (accurracy)\n",
    "    y_predicted = model.predict(X_test.values)\n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "    print(f\"[{name}]: accuracy = {accuracy}\")\n",
    "\n",
    "    try:\n",
    "        train_predictions = model.predict_proba(X_test.values)\n",
    "        loss = log_loss(y_test, train_predictions)\n",
    "        print(f\"[{name}]: log loss = {loss}\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    models[name] = model\n",
    "\n",
    "    # incorrect_indices = [i for i in range(len(y_test)) if y_test[i] != y_predicted[i]]\n",
    "    # incorrect_predictions = [(y_test[i], y_predicted[i]) for i in incorrect_indices]\n",
    "\n",
    "    # # Print the actual incorrect predictions\n",
    "    # print(\"Incorrect predictions:\")\n",
    "    # for true_label, predicted_label in incorrect_predictions:\n",
    "    #     print(f\"True: {true_label}, Predicted: {predicted_label}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "selected_model = models[\"RandomForestClassifier\"]\n",
    "\n",
    "with open(\"handy_classifier.pkl\", \"wb\") as f:\n",
    "    pickle.dump(selected_model, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "handy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
